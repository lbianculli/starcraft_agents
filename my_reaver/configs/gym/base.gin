# params for generic actor-critic:
# ==========================================
build_mlp.activation = 'relu'
build_mlp.value_separate = True
build_mlp.obs_shift = True
build_mlp.obs_scale = False

ACAgent.model_fn = @build_mlp
ACAgent.policy_cls = @MultiPolicy

ACAgent.optimizer = @tf.train.AdamOptimizer()
tf.train.AdamOptimizer.learning_rate = 0.0003

ACAgent.value_coef = 0.5
ACAgent.entropy_coef = 0.01

ACAgent.batch_sz = 16
ACAgent.traj_len = 8

ACAgent.discount = 0.99
ACAgent.gae_lambda = 0.0

ACAgent.clip_rewards = 0.0
ACAgent.clip_grads_norm = 1.0

ACAgent.normalize_advantages = False

# params for A2C:
# ==========================================
# ...

# params for PPO:
# ==========================================
PPOAgent.n_epochs = 3
PPOAgent.minibatch_sz = 128
PPOAgent.clip_ratio = 0.2
PPOAgent.clip_value = 0.0